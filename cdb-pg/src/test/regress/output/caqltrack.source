-- --------------------------------------
-- caqltrack
-- --------------------------------------
-- *********************************************************************
-- *********************************************************************
-- This script tests if we add coverage for caql callers.
-- It has many ignore blocks containing caql usage information.
--
-- If you want to change the results, you must
-- make the changes in regress/output/caqltrack.source, not
-- regress/expected, and use gpsourcify.pl to generate a ".source"
-- file.
--
-- From the regress directory invoke the command:
--
--    gpsourcify.pl results/caqltrack.out  > output/caqltrack.source
--
-- To run this test, CaQL should be built with logquery option.
-- Set environment variable with caql_logquery_FLAGS='-logquery'
-- *********************************************************************
-- *********************************************************************
-- *********************************************************************
-- *********************************************************************
-- start_ignore
drop database if exists caqltrack_db;
drop role caql_super_luser;
-- end_ignore
-- create a table, insert some rows, do a query, drop it.
-- after we build the caql log tables, we can profile the catalog usage
-- for each statement
CREATE TABLE CQTxxx_1 (a int, b int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
INSERT INTO CQTxxx_1 SELECT ii, ii*2 from generate_series(1,1000) as ii;
SELECT avg(a), avg(b) FROM CQTxxx_1;
  avg  | avg  
-------+------
 500.5 | 1001
(1 row)

DROP TABLE CQTxxx_1;
-- need a superuser and a new database that has the toolkit views
-- (which are *not* in regression)
create user caql_super_luser SUPERUSER;
set role caql_super_luser;
create database caqltrack_db;
\c caqltrack_db
set role caql_super_luser;
set gp_enable_caql_logging=false;
-- \d gp_toolkit.__gp_log_master_ext;
-- start_ignore
DROP TABLE caql_master_t1;
DROP TABLE caql_segment_t1;
drop view caql_log_system;
drop view caql_master_m1;
drop view caql_master_v1;
-- end_ignore
-- *********************************************************************
-- *********************************************************************
-- This load process is convoluted to avoid a weird problem where
-- SELECTing from the csv log file (using an external table and
-- regex_split_to_array() ) resulted in a catalog operation per row
-- ("SELECT * FROM pg_type WHERE oid = :1" , from
-- lsyscache.c/get_typlenbyvalalign() ), such that the log file would
-- grow without bound as we read from it, and the query would never
-- end.  The caqltrack load process was restructured to disable query
-- logging (which only works partially) and then copy the contents of
-- the log to heap tables using simple queries, and then the complex
-- processing is performed in-database.
-- *********************************************************************
-- *********************************************************************
CREATE view caql_master_m1
as select
    'master'::varchar as caql_masterseg,
    logtime,
    loguser,
    logdatabase,
    logpid,
    logthread,
    loghost,
    logport,
    logsessiontime,
    logtransaction,
    logsession,
    logcmdcount,
    logsegment,
    logslice,
    logdistxact,
    loglocalxact,
    logsubxact,
    logseverity,
    logstate,
    logmessage,
    logdetail,
    loghint,
    logquery,
    logquerypos,
    logcontext,
    logdebug,
    logcursorpos,
    logfunction,
    logfile,
    logline,
    logstack
from
gp_toolkit.__gp_log_master_ext
where logmessage like ('catquery:%');
CREATE TABLE caql_master_t1
as select * from caql_master_m1 distributed by (logtime);
CREATE VIEW caql_master_v1
as SELECT
    caql_masterseg,
    logtime,
    loguser,
    logdatabase,
    logpid,
    logthread,
    loghost,
    logport,
    logsessiontime,
    logtransaction,
    logsession,
    logcmdcount,
    logsegment,
    logslice,
    logdistxact,
    loglocalxact,
    logsubxact,
    logseverity,
    logstate,
regexp_split_to_array(
regexp_replace(
regexp_replace(logmessage,
'catquery: caql_basic_fn_', ''), 'caller: ', ''), ' ') as caql_mess_arr,
    logmessage,
    logdetail,
    loghint,
    logquery,
    logquerypos,
    logcontext,
    logdebug,
    logcursorpos,
    logfunction,
    logfile,
    logline,
    logstack
from
caql_master_t1;
-- start_ignore
drop view caql_segment_m1;
ERROR:  view "caql_segment_m1" does not exist
drop view caql_segment_v1;
ERROR:  view "caql_segment_v1" does not exist
-- end_ignore
CREATE view caql_segment_m1
as select
    'segment'::varchar as caql_masterseg,
    logtime,
    loguser,
    logdatabase,
    logpid,
    logthread,
    loghost,
    logport,
    logsessiontime,
    logtransaction,
    logsession,
    logcmdcount,
    logsegment,
    logslice,
    logdistxact,
    loglocalxact,
    logsubxact,
    logseverity,
    logstate,
    logmessage,
    logdetail,
    loghint,
    logquery,
    logquerypos,
    logcontext,
    logdebug,
    logcursorpos,
    logfunction,
    logfile,
    logline,
    logstack
from
gp_toolkit.__gp_log_segment_ext
where logmessage like ('catquery:%');
CREATE TABLE caql_segment_t1
as select * from caql_segment_m1 distributed by (logtime);
CREATE VIEW caql_segment_v1
AS SELECT
    caql_masterseg,
    logtime,
    loguser,
    logdatabase,
    logpid,
    logthread,
    loghost,
    logport,
    logsessiontime,
    logtransaction,
    logsession,
    logcmdcount,
    logsegment,
    logslice,
    logdistxact,
    loglocalxact,
    logsubxact,
    logseverity,
    logstate,
regexp_split_to_array(
regexp_replace(
regexp_replace(logmessage,
'catquery: caql_basic_fn_', ''), 'caller: ', ''), ' ') as caql_mess_arr,
    logmessage,
    logdetail,
    loghint,
    logquery,
    logquerypos,
    logcontext,
    logdebug,
    logcursorpos,
    logfunction,
    logfile,
    logline,
    logstack
FROM
caql_segment_t1;
CREATE VIEW caql_log_system
AS
    select
    caql_masterseg,
    logtime,
    loguser,
    logdatabase,
    logpid,
    logthread,
    loghost,
    logport,
    logsessiontime,
    logtransaction,
    logsession,
    logcmdcount,
    logsegment,
    logslice,
    logdistxact,
    loglocalxact,
    logsubxact,
    logseverity,
    logstate,
    caql_mess_arr[1] as caql_basequery_code,
    caql_mess_arr[2] as caql_module,
    caql_mess_arr[3] as caql_lineno,
    caql_mess_arr[4] as caql_uniqquery_code,
    caql_mess_arr[5] as caql_firstarg,
    logmessage,
    logdetail,
    loghint,
    logquery,
    logquerypos,
    logcontext,
    logdebug,
    logcursorpos,
    logfunction,
    logfile,
    logline,
    logstack
    from
(
    SELECT * FROM caql_segment_v1
    UNION ALL
    SELECT * FROM caql_master_v1
) as foo
;
-- --------------------------------------
-- get "unique" caql queries from calico
-- --------------------------------------
drop external web table if exists get_uniqdef;
NOTICE:  table "get_uniqdef" does not exist, skipping
CREATE EXTERNAL WEB TABLE get_uniqdef (x text)
execute E'( perl @abs_srcdir@/../../include/catalog/caqluniqdef.pl  @abs_srcdir@/../../backend/access/index/uniqdef.json > @abs_srcdir@/data/uniqdef.data )'
on SEGMENT 0
format 'text';
-- start_ignore
select * from get_uniqdef;
-- end_ignore
drop external table if exists EXT_uniqdef;
NOTICE:  table "ext_uniqdef" does not exist, skipping
CREATE EXTERNAL TABLE EXT_uniqdef (
      uniq_qry text,
      bcount integer,
      bdelete integer,
      binsert integer,
      bupdate integer,
      basequery_code integer,
      base_qry text,
      colnum char(64),
      cql char(6),
      tablename char(64),
      uniqquery_code integer)
location ('file://@hostname@@abs_srcdir@/data/uniqdef.data' )
   FORMAT 'text' (delimiter '|');
create table udef as select * from EXT_uniqdef;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'uniq_qry' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
create table cq_logall as select * from caql_log_system
distributed by (logtime);
-- --------------------------------------
-- get caql caller location
-- --------------------------------------
-- start_ignore
drop external web table if exists get_caloc;
NOTICE:  table "get_caloc" does not exist, skipping
drop table if exists caloc;
NOTICE:  table "caloc" does not exist, skipping
drop table if exists caller;
NOTICE:  table "caller" does not exist, skipping
-- end_ignore
CREATE EXTERNAL WEB TABLE get_caloc (query text, file text, lineno integer, path text)
execute E'python @abs_srcdir@/../../backend/access/index/caller.py'
on MASTER format 'text';
create table caloc as select * from get_caloc;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'query' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
-- start_ignore
select count(*) from caloc;
 count 
-------
   807
(1 row)

-- end_ignore
-- --------------------------------------
-- get caql caller from the log
-- --------------------------------------
create table caller (fn text, file text, lineno int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'fn' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into caller
    select distinct substring(logmessage from 'caql_basic_fn_[0-9]*'),
                    substring(logmessage from '.*: .*: (.*.c)'),
                    substring(logmessage from '.* ([0-9]*) [0-9]* [0-9]*')::int from caql_master_t1
    union
    select distinct substring(logmessage from 'caql_basic_fn_[0-9]*'),
                    substring(logmessage from '.*: .*: (.*.c)'),
                    substring(logmessage from '.* ([0-9]*) [0-9]* [0-9]*')::int from caql_segment_t1
;
-- --------------------------------------
-- caql callers that are not yet tested
-- --------------------------------------
select count(*)
  from caloc left join caller using(file, lineno)
 where caller.fn is null;
 count
-------
     0
(1 row)

select path, file, lineno
  from caloc left join caller using(file, lineno)
 where caller.fn is null
 order by 1, 3;
 path | file | lineno 
------+------+--------
(0 rows)

-- start_ignore
select caql_masterseg, count(*) from cq_logall group by caql_masterseg;
select count(distinct caql_basequery_code) from cq_logall;
select count(distinct basequery_code) from udef;
select caql_masterseg, count(distinct caql_basequery_code)
from cq_logall group by caql_masterseg;
select count(distinct caql_uniqquery_code) from cq_logall;
select count(distinct uniqquery_code) from udef;
select caql_masterseg, count(distinct caql_uniqquery_code)

-- base query counts
select tablename, base_qry, count(base_qry) as qcount
from udef u, cq_logall la
where
u.basequery_code = la.caql_basequery_code
group by tablename, base_qry
order by qcount desc;
 tablename | base_qry | qcount 
-----------+----------+--------
(0 rows)

-- uniq query counts
select tablename, base_qry, uniq_qry, count(uniq_qry) as qcount
from udef u, cq_logall la
where
u.uniqquery_code = la.caql_uniqquery_code
group by tablename, base_qry, uniq_qry
order by qcount desc;
 tablename | base_qry | uniq_qry | qcount 
-----------+----------+----------+--------
(0 rows)

-- missing base query
select tablename, base_qry
from udef u
where
u.basequery_code not in
(select caql_basequery_code from cq_logall)
order by 1,2;
 tablename | base_qry 
-----------+----------
(0 rows)

-- missing uniq query
select tablename, uniq_qry
from udef u
where
u.uniqquery_code not in
(select caql_uniqquery_code from cq_logall)
order by 1,2;
 tablename | uniq_qry 
-----------+----------
(0 rows)

-- tables without insert/update/delete (overall)
select tablename from udef group by tablename having sum(bdelete)=0
and sum(binsert)=0 and sum(bupdate)=0;
 tablename 
-----------
(0 rows)

-- tables without insert/update/delete (as logged)
select tablename
from udef u
where
u.uniqquery_code in
(select caql_uniqquery_code from cq_logall)
group by tablename
having
sum(bdelete)=0 and
sum(binsert)=0 and
sum(bupdate)=0
order by 1;
 tablename 
-----------
(0 rows)

-- cleanup

drop view caql_log_system;
drop view caql_master_v1;
drop view caql_segment_v1;
drop view caql_master_m1;
drop view caql_segment_m1;
drop table caql_master_t1;
drop table caql_segment_t1;

drop external web table if exists get_uniqdef;
drop external table if exists EXT_uniqdef;

drop table udef;
drop table if exists cq_logall;
*/
-- back to normal
\c regression
reset role;
drop role caql_super_luser ;
drop database caqltrack_db;
-- end_ignore

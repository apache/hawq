--
-- PXF HIVE regression suite 
--
-- Prerequisites:
--
--   Must have a running hdfs with REST service on port 50070
--   Must have a running YARN services (to load data into Hive).
--   Must have HADOOP_ROOT, HBASE_ROOT, HIVE_ROOT and ZOOKEEPER_ROOT set.
--   PATH=${PATH}:${HADOOP_ROOT}/bin/
--
-- TODO: test gpdbwritable write/read when it is enabled.
-- TODO: test PB, AVRO, THRIFT when it is enabled (read only, with pre formatted files).
-- TODO: test protocol validator for pxf once written.
-- TODO: test parameter passing, filter passing

-- start_matchsubs
--                                                                                               
-- # create a match/subs expression to handle ip addresses that change
--
-- m/(ERROR|WARNING):.*remote component error.*\(\d+\).*from.*'\d+\.\d+\.\d+\.\d+:\d+'.*/
-- s/'\d+\.\d+\.\d+\.\d+:\d+'/'SOME_IP:SOME_PORT'/
--
-- end_matchsubs

--------------------------------------------------------------------------------
-- HIVE
--------------------------------------------------------------------------------
--

-- 1. Testing Hive support for the primitive data types
\! ${HIVE_ROOT}/bin/hive -e "create table hive_types (s1 string,s2 string,n1 int, d1 double, dc1 decimal, tm timestamp, f float, bg bigint, b boolean)row format delimited fields terminated by ','" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "load data local inpath '@abs_srcdir@/data/pxf/hive_types.txt' into table hive_types" 2>/dev/null

CREATE EXTERNAL TABLE hawq_types(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision,
dec1  numeric,
tm timestamp,
r real,
bg bigint,
b boolean)
LOCATION ('pxf://@hostname@:50070/hive_types?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hawq_types order by t1;

-- 2. Hive table stored as text
\! ${HIVE_ROOT}/bin/hive -e "create table reg_txt (s1 string,s2 string,n1 int, d1 double)row format delimited fields terminated by ','" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "load data local inpath '@abs_srcdir@/data/pxf/hive_small_data.txt' into table reg_txt" 2>/dev/null

CREATE EXTERNAL TABLE hv_txt(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision)
LOCATION ('pxf://@hostname@:50070/reg_txt?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_txt order by t1;

-- 3. Hive table stored as sequence
\! ${HIVE_ROOT}/bin/hive -e "create table reg_seq (t0 string, t1 string, num1 int, d1 double) row format delimited fields terminated by ',' STORED AS SEQUENCEFILE" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "insert into table reg_seq select * from reg_txt" 2>/dev/null

CREATE EXTERNAL TABLE hv_seq(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision)
LOCATION ('pxf://@hostname@:50070/reg_seq?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_seq order by t1;

-- 4. Hive table stored as rcfile
\! ${HIVE_ROOT}/bin/hive -e "create table reg_rc (t0 string, t1 string, num1 int, d1 double) STORED AS RCFILE" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "insert into table reg_rc select * from reg_txt" 2>/dev/null

CREATE EXTERNAL TABLE hv_rc(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision)
LOCATION ('pxf://@hostname@:50070/reg_rc?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_rc order by t1;

-- 5. Hive table stored as orc
\! ${HIVE_ROOT}/bin/hive -e "create table reg_orc (t0 string, t1 string, num1 int, d1 double) STORED AS ORC" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "insert into table reg_orc select * from reg_txt" 2>/dev/null

CREATE EXTERNAL TABLE hv_orc(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision)
LOCATION ('pxf://@hostname@:50070/reg_orc?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_orc order by t1;

-- 6. Hive table stored in several partitions where each partition is stored in a diferrent format
\! ${HIVE_ROOT}/bin/hive -e "create external table reg_heterogen (s1 string,s2 string,n1 int, d1 double) partitioned by (fmt string)  row format delimited fields terminated by ','" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "alter table reg_heterogen add partition (fmt = 'txt') location 'hdfs:/hive/warehouse/reg_txt'" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "alter table reg_heterogen add partition (fmt = 'rc') location 'hdfs:/hive/warehouse/reg_rc'" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "alter table reg_heterogen add partition (fmt = 'seq') location 'hdfs:/hive/warehouse/reg_seq'" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "alter table reg_heterogen add partition (fmt = 'orc') location 'hdfs:/hive/warehouse/reg_orc'" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "alter table reg_heterogen partition (fmt='rc') set fileformat RCFILE" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "alter table reg_heterogen partition (fmt='seq') set fileformat SEQUENCEFILE" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "alter table reg_heterogen partition (fmt='orc') set fileformat ORC" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "show partitions reg_heterogen" 2>/dev/null

CREATE EXTERNAL TABLE hv_heterogen(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision,
t3 text)
LOCATION ('pxf://@hostname@:50070/reg_heterogen?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_heterogen order by t3, t1;

-- Test analyze for Hive table.
ANALYZE hv_heterogen;
select relpages, reltuples from pg_class where relname = 'hv_heterogen';

-- 7. Hive table with collection types (non primitive types)
\! ${HIVE_ROOT}/bin/hive -e "CREATE TABLE reg_collections ( s1 STRING, f1 FLOAT, a1 ARRAY<STRING> , m1 MAP<STRING,  FLOAT > , sr1 STRUCT<street:STRING,  city:STRING,  state:STRING,  zip:INT > )  ROW FORMAT DELIMITED  FIELDS TERMINATED BY '\001' COLLECTION ITEMS TERMINATED BY '\002' MAP KEYS TERMINATED BY '\003'  LINES TERMINATED BY '\n'  STORED AS TEXTFILE" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "load data local inpath '@abs_srcdir@/data/pxf/hive_collections.txt' into table reg_collections" 2>/dev/null

CREATE EXTERNAL TABLE hv_collections(
t1    text,   
f1    real,
t2    text, 
t3    text, 
t4    text,
t5    text, 
f2    real,
t6    text,
f3    real,
t7    text,
t8    text,
t9    text,
num1  integer)
LOCATION ('pxf://@hostname@:50070/reg_collections?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_collections order by t1;

-- 8. View - negative test
\! ${HIVE_ROOT}/bin/hive -e "create view reg_txt_view as select s1 from reg_txt" 2>/dev/null

CREATE EXTERNAL TABLE hv_view(
t1    text)
LOCATION ('pxf://@hostname@:50070/reg_txt_view?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_view order by t1;

-- 9.  Decimal is a partition in the Hive Table
\! ${HIVE_ROOT}/bin/hive -e "create table part_dec (s1 string,s2 string,n1 int, d1 double) partitioned by (dec decimal)  row format delimited fields terminated by ','" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "load data local inpath '@abs_srcdir@/data/pxf/hive_small_data.txt' into table part_dec partition (dec = 10.1111111111111)" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "load data local inpath '@abs_srcdir@/data/pxf/hive_small_data.txt' into table part_dec partition (dec = 10.2222222222222)" 2>/dev/null

CREATE EXTERNAL TABLE hv_part_dec(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision,
dec1  numeric)
LOCATION ('pxf://@hostname@:50070/part_dec?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_part_dec order by dec1, t1;
select * from hv_part_dec where dec1 = 10.2222222222222 order by t1;

-- 10.  Unknown Type - negative test
\! ${HIVE_ROOT}/bin/hive -e "create table un_supported_tbl (s1 string,s2 string,n1 tinyint, n2 int)row format delimited fields terminated by ','" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "load data local inpath '@abs_srcdir@/data/pxf/hive_small_data.txt' into table un_supported_tbl" 2>/dev/null

CREATE EXTERNAL TABLE hv_un_supported_tbl(
t1    text,
t2    text,  
num1  integer, 
num2  integer)
LOCATION ('pxf://@hostname@:50070/un_supported_tbl?FRAGMENTER=HiveDataFragmenter&ACCESSOR=HiveAccessor&RESOLVER=HiveResolver')
format 'custom' (formatter='pxfwritable_import');
select * from hv_un_supported_tbl;

-- 11.  Create external table with Profile option
CREATE EXTERNAL TABLE tbl_with_profile(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision)
LOCATION ('pxf://@hostname@:50070/reg_seq?PROFILE=HIVE')
format 'custom' (formatter='pxfwritable_import');
select * from tbl_with_profile order by t1;

-- 12. Test analyze for Hive table with profile without analyzer - negative test
CREATE EXTERNAL TABLE hv_heterogen_profile_wo_analyzer(
t1    text,
t2    text,  
num1  integer, 
dub1  double precision,
t3 text)
LOCATION ('pxf://@hostname@:50070/reg_heterogen?PROFILE=Hive')
format 'custom' (formatter='pxfwritable_import');
ANALYZE hv_heterogen_profile_wo_analyzer;

-- 13. Index table
\! ${HIVE_ROOT}/bin/hive -e "create index reg_txt_index on table reg_txt (s1) as 'COMPACT' with deferred rebuild" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "alter index reg_txt_index on reg_txt rebuild" 2>/dev/null
CREATE EXTERNAL TABLE hv_index(
t1    text,
t2    text,
n1 bigint)
LOCATION ('pxf://@hostname@:50070/default__reg_txt_reg_txt_index__?PROFILE=Hive')
FORMAT 'CUSTOM' (formatter='pxfwritable_import');
SELECT * FROM hv_index ORDER BY t1;

-- 14. Clean after Hive
drop external table hv_index;
drop external table hv_view;
drop external table hv_collections;
drop external table hv_heterogen;
drop external table hv_orc;
drop external table hv_rc;
drop external table hv_seq;
drop external table hv_txt;
drop external table hawq_types;
drop external table hv_part_dec;
drop external table hv_un_supported_tbl;
drop external table tbl_with_profile;
drop external table hv_heterogen_profile_wo_analyzer;

\! ${HIVE_ROOT}/bin/hive -e "drop index reg_index on reg_txt" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table default__reg_txt_reg_txt_index__" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop view reg_txt_view" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table reg_collections" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table reg_heterogen" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table reg_orc" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table reg_rc" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table reg_seq" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table reg_txt" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table hive_types" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table part_dec" 2>/dev/null
\! ${HIVE_ROOT}/bin/hive -e "drop table un_supported_tbl" 2>/dev/null

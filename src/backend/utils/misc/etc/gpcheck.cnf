[global]
configfile_version = 4

[linux.mount]
mount.points = /

[linux.sysctl]
sysctl.kernel.shmmax = 1000000000
sysctl.kernel.shmmni = 4096
sysctl.kernel.shmall = 4000000000
sysctl.kernel.sem = 250 512000 100 2048
sysctl.kernel.sysrq = 1
sysctl.kernel.core_uses_pid = 1
sysctl.kernel.msgmnb = 65536
sysctl.kernel.msgmax = 65536
sysctl.kernel.msgmni = 2048
sysctl.net.ipv4.tcp_syncookies = 0
sysctl.net.ipv4.ip_forward = 0
sysctl.net.ipv4.conf.default.accept_source_route = 0
sysctl.net.ipv4.tcp_tw_recycle = 1
sysctl.net.ipv4.tcp_max_syn_backlog = 200000
sysctl.net.ipv4.conf.all.arp_filter = 1
sysctl.net.ipv4.ip_local_port_range = 1281 65535
sysctl.net.core.netdev_max_backlog = 200000
sysctl.vm.overcommit_memory = 2
sysctl.fs.nr_open = 3000000
sysctl.kernel.threads-max = 798720
sysctl.kernel.pid_max = 798720
# increase network
sysctl.net.core.rmem_max = 2097152
sysctl.net.core.wmem_max = 2097152

[linux.limits]
soft.nofile = 2900000
hard.nofile = 2900000
soft.nproc  = 131072
hard.nproc  = 131072

[linux.diskusage]
diskusage.monitor.mounts = /
diskusage.monitor.usagemax = 90%

[hdfs.base]
dfs.mem.namenode.heap = 40960
dfs.mem.datanode.heap = 6144
# in hdfs-site.xml
dfs.support.append = true
dfs.block.local-path-access.user = gpadmin
dfs.datanode.max.transfer.threads = 40960
dfs.client.socket-timeout = 300000000
dfs.datanode.socket.write.timeout = 7200000
dfs.namenode.handler.count = 60
ipc.server.handler.queue.size = 3300
dfs.datanode.handler.count = 60
ipc.client.connection.maxidletime = 3600000
dfs.namenode.accesstime.precision = 0
dfs.client.read.shortcircuit = true

[hdfs.non]
dfs.block.access.token.enable = FALSE

[hdfs.ha]
dfs.block.access.token.enable = FALSE

[hdfs.kerberos]
dfs.block.access.token.enable = TRUE
dfs.datanode.data.dir.perm = 750

[hdfs.ha.kerberos]
dfs.block.access.token.enable = TRUE

[yarn.base]
yarn.resourcemanager.scheduler.class = org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler

[yarn.non]

[yarn.ha]

[yarn.kerberos]
hadoop.security.authentication = kerberos
hadoop.proxyuser.yarn.groups = *
hadoop.proxyuser.yarn.hosts = *
hadoop.proxyuser.postgres.hosts = *
hadoop.proxyuser.postgres.groups = *

[yarn.ha.kerberos]
hadoop.security.authentication = kerberos
hadoop.proxyuser.yarn.groups = *
hadoop.proxyuser.yarn.hosts = *
hadoop.proxyuser.postgres.hosts = *
hadoop.proxyuser.postgres.groups = *

[hawq.base]
dfs.client.read.shortcircuit = true

[hawq.kerberos]
hadoop.security.authentication = kerberos

[hawq.yarn]
hawq_global_rm_type = yarn

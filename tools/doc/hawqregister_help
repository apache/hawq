COMMAND NAME: hawq register

Usage1: Register parquet files generated by other system into the corrsponding table in HAWQ
Usage2: Register parquet/ao table from laterst-sync-metadata in yaml format

*****************************************************
SYNOPSIS
*****************************************************

Usage1: hawq register [-h hostname] [-p port] [-U username] [-d databasename] [-f filepath] <tablename>
Usage2: hawq register [-h hostname] [-p port] [-U username] [-d databasename] [-c config] <tablename>

hawq register help
hawq register -?

hawq register --version

*****************************************************
DESCRIPTION
*****************************************************

Use Case1:
"hawq register" is a utility to register file(s) on HDFS into
the table in HAWQ. It moves the file in the path(if path
refers to a file) or files under the path(if path refers to a
directory) into the table directory corresponding to the table,
and then update the table meta data to include the files.

To use "hawq register", HAWQ must have been started.

Currently "hawq register" supports parquet tables only.
User have to make sure that the meta data of the parquet file(s)
and the table are consistent.
The table to be registered into should not be hash distributed, which
is created by using "distributed by" statement when creating that table.
The file(s) to be registered and the table in HAWQ must be in the
same HDFS cluster.

Use Case2:
User should be able to use hawq register to register table files into a new HAWQ cluster.
It is some kind of protecting against corruption from users' perspective.
Users use the last-known-good metadata to update the portion of catalog managing HDFS blocks.
The table files or dictionary should be backuped(such as using distcp) into the same path in the new HDFS setting.

To use "hawq register", HAWQ must have been started.
Currently "hawq register" supports both AO and Parquet formats in this case.
The partition table is not supported in this version, and we will support it soon.

*****************************************************
Arguments
*****************************************************

<tablename>

Name of the table to be registered into.

*****************************************************
OPTIONS
*****************************************************

-? (help)

Displays the online help.

--version

Displays the version of this utility.

*****************************************************
CONNECTION OPTIONS
*****************************************************

-h hostname

  Specifies the host name of the machine on which the HAWQ master
  database server is running. If not specified, reads from the
  environment variable $PGHOST which defaults to localhost.

-p port

  Specifies the TCP port on which the HAWQ master database server
  is listening for connections. If not specified, reads from the
  environment variable $PGPORT which defaults to 5432.

-U username

  The database role name to connect as. If not specified, reads
  from the environment variable $PGUSER which defaults to the current
  system user name.

*****************************************************
EXAMPLE FOR USAGE1
*****************************************************

Run "hawq register" to register a parquet file in HDFS with path
'hdfs://localhost:8020/temp/hive.paq' generated by hive into table
'parquet_table' in HAWQ, which is in the database named 'postgres'.

Assume the location of the database is 'hdfs://localhost:8020/hawq_default',
tablespace id is '16385', database id is '16387', table filenode id is '77160',
last file under the filenode numbered '7'.

$ hawq register postgres parquet_table hdfs://localhost:8020/temp/hive.paq

This will move the file 'hdfs://localhost:8020/temp/hive.paq' into the corresponding
new place 'hdfs://localhost:8020/hawq_default/16385/16387/77160/8' in HDFS, then
update the meta data of the table 'parquet_table' in HAWQ which is in the
table 'pg_aoseg.pg_paqseg_77160'.

*****************************************************
EXAMPLE FOR USAGE2
*****************************************************
$ psql -c "drop table if exists table;"
$ psql -c "create table table(i int) with (appendonly=true, orientation=parquet) distributed by (i);"
$ psql -c "insert into table values(1), (2), (3);"
$ hawq extract -d postgres -o t.yml table
$ hawq register -d postgres -c t.yml newtable
In this example, suppose that "table" is a table in old HAWQ Cluster, user dump "t.yml" yaml file to
save the metadata of "table". To register the "newtable" in a new HAWQ Cluster, user run "hawq register"
to register the newtable with the given yaml file "t.yml".

*****************************************************
DATA TYPES
*****************************************************
The data types used in HAWQ and parquet format are not the same, so there is a
mapping between them, concluded as follow:

Data types in HAWQ              Data types in parquet
bool                            boolean
int2                            int32
int4                            int32
date                            int32
int8                            int64
time                            int64
timestamptz                     int64
timestamp                       int64
money                           int64
float4                          float
float8                          double
bit                             byte_array
varbit                          byte_array
byte                            byte_array
numeric                         byte_array
name                            byte_array
char                            byte_array
bpchar                          byte_array
varchar                         byte_array
text                            byte_array
xml                             byte_array
timetz                          byte_array
interval                        byte_array
macaddr                         byte_array
inet                            byte_array
cidr                            byte_array
